{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a6334-6bb3-4c76-a63b-87cdbebbdd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '16'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Código para cargar y pivotar los datos ---\n",
    "db_file_path = 'planta_quimica.db'\n",
    "conn = sqlite3.connect(db_file_path)\n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "        timestamp,\n",
    "        MAX(CASE WHEN sensor_id = 'temp_1' THEN valor END) AS temp_1,\n",
    "        MAX(CASE WHEN sensor_id = 'temp_2' THEN valor END) AS temp_2,\n",
    "        MAX(CASE WHEN sensor_id = 'temp_3' THEN valor END) AS temp_3,\n",
    "        MAX(CASE WHEN sensor_id = 'pres_1' THEN valor END) AS pres_1,\n",
    "        MAX(CASE WHEN sensor_id = 'pres_2' THEN valor END) AS pres_2\n",
    "    FROM\n",
    "        lecturas_sensores\n",
    "    GROUP BY\n",
    "        timestamp;\n",
    "\"\"\"\n",
    "df_ancho = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "# ------------------------------------------------\n",
    "\n",
    "# 1. Preparar los datos para el clustering\n",
    "#    Nos quedamos solo con las columnas numéricas y las estandarizamos\n",
    "features = df_ancho.drop('timestamp', axis=1)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "\n",
    "# 2. Calcular Codo y Silueta para diferentes valores de K\n",
    "k_values = range(2, 11) # Probaremos de 2 a 10 clusters\n",
    "inertia_values = []\n",
    "silhouette_values = []\n",
    "\n",
    "print(\"Calculando scores para diferentes números de clusters...\")\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(features_scaled)\n",
    "    \n",
    "    # Para el método del codo\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "    \n",
    "    # Para el análisis de silueta\n",
    "    silhouette_values.append(silhouette_score(features_scaled, kmeans.labels_))\n",
    "\n",
    "# 3. Graficar los resultados\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Gráfico del Codo\n",
    "ax1.plot(k_values, inertia_values, 'bo-')\n",
    "ax1.set_title('Método del Codo')\n",
    "ax1.set_xlabel('Número de Clusters (K)')\n",
    "ax1.set_ylabel('Inercia')\n",
    "\n",
    "# Gráfico de Silueta\n",
    "ax2.plot(k_values, silhouette_values, 'ro-')\n",
    "ax2.set_title('Análisis de Silueta')\n",
    "ax2.set_xlabel('Número de Clusters (K)')\n",
    "ax2.set_ylabel('Score de Silueta')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 1. Crear y entrenar el modelo K-Means final con K=6\n",
    "print(\"Entrenando el modelo K-Means con 6 clusters...\")\n",
    "kmeans_final = KMeans(n_clusters=6, random_state=42, n_init=10)\n",
    "kmeans_final.fit(features_scaled)\n",
    "\n",
    "# 2. Añadir las etiquetas del cluster a nuestra tabla original\n",
    "df_ancho['cluster'] = kmeans_final.labels_\n",
    "\n",
    "# 3. Mostrar las primeras filas con la nueva columna 'cluster'\n",
    "print(\"\\nTabla con la columna de cluster añadida:\")\n",
    "print(df_ancho.head())\n",
    "\n",
    "# 4. Contar cuántos puntos hay en cada cluster\n",
    "print(\"\\nDistribución de puntos por cluster:\")\n",
    "print(df_ancho['cluster'].value_counts())\n",
    "\n",
    "# 1. Seleccionar solo las columnas numéricas antes de agrupar\n",
    "df_numerico = df_ancho.drop('timestamp', axis=1)\n",
    "\n",
    "# 2. Agrupar por la columna 'cluster' y calcular el promedio\n",
    "cluster_profiles = df_numerico.groupby('cluster').mean()\n",
    "\n",
    "# 3. Imprimir la tabla de perfiles\n",
    "print(\"--- Perfiles de los Clusters (Valores Promedio de Sensores) ---\")\n",
    "print(cluster_profiles)\n",
    "\n",
    "# 1. Entrenar el modelo final con K=6\n",
    "kmeans_final = KMeans(n_clusters=6, random_state=42, n_init=10)\n",
    "kmeans_final.fit(features_scaled)\n",
    "\n",
    "# 2. Calcular la distancia de cada punto al centroide de su cluster\n",
    "#    Esto nos da una \"puntuación de anomalía\"\n",
    "distancias = kmeans_final.transform(features_scaled)\n",
    "distancia_minima = np.min(distancias, axis=1)\n",
    "df_ancho['distancia_anomalia'] = distancia_minima\n",
    "\n",
    "# 3. Ordenar el DataFrame para encontrar las lecturas más anómalas\n",
    "df_anomalias = df_ancho.sort_values(by='distancia_anomalia', ascending=False)\n",
    "\n",
    "# 4. Mostrar las 5 lecturas más anómalas\n",
    "print(\"--- TOP 5 LECTURAS MÁS ANÓMALAS DETECTADAS ---\")\n",
    "print(df_anomalias.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580d493-ae46-49d2-be63-bc9ef13034d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
